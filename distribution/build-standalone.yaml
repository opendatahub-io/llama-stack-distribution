version: "2"
distribution_spec:
  description: Red Hat distribution of Llama Stack (Standalone Docker)
  providers:
    inference:
    - "remote::vllm"
    - "inline::sentence-transformers"
    vector_io:
    - "inline::milvus"
    safety:
    - "inline::llama-guard"
    agents:
    - "inline::meta-reference"
    # eval: removed trustyai_lmeval provider for standalone Docker
    datasetio:
    - "remote::huggingface"
    - "inline::localfs"
    scoring:
    - "inline::basic"
    - "inline::llm-as-judge"
    - "inline::braintrust"
    telemetry:
    - "inline::meta-reference"
    tool_runtime:
    - "remote::brave-search"
    - "remote::tavily-search"
    - "inline::rag-runtime"
    - "remote::model-context-protocol"
  container_image: registry.redhat.io/ubi9/python-311:9.6-1749631027
additional_pip_packages:
- aiosqlite
- sqlalchemy[asyncio]
image_type: container
image_name: llama-stack-rh-standalone
# external_providers_dir: distribution/providers.d  # Disabled for standalone mode
