name: Live CI tests

on:
  schedule:
    - cron: '0 2 * * 1' # Every Monday at 2 AM UTC
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event_name }}
  cancel-in-progress: false

env:
  REGISTRY: quay.io
  IMAGE_NAME: quay.io/opendatahub/llama-stack
  LLAMA_STACK_TEST_INFERENCE_MODE: live

jobs:
  live-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      id-token: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Check required secrets
        run: |
          if [ -z "${{ secrets.VERTEX_AI_PROJECT }}" ] || [ -z "${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}" ]; then
            echo "Error: VERTEX_AI_PROJECT and GCP_WORKLOAD_IDENTITY_PROVIDER secrets must be set"
            exit 1
          fi

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure gcloud
        run: |
          gcloud config set project ${{ secrets.VERTEX_AI_PROJECT }}
          gcloud config set compute/region us-central1

      - name: Install uv
        uses: astral-sh/setup-uv@5a7eac68fb9809dea845d802897dc5c723910fa3 # v7.1.3
        with:
          python-version: 3.12
          version: 0.7.6

      - name: Build image
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0
        with:
          context: .
          file: distribution/Containerfile
          platforms: linux/amd64
          push: false
          tags: ${{ env.IMAGE_NAME }}:vertex-test-${{ github.sha }}
          load: true
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Start Llama Stack container
        run: |
          docker run -d --net=host -p 8321:8321 \
            -v "$HOME/.config/gcloud:/root/.config/gcloud:ro" \
            -e VERTEX_AI_PROJECT="${{ secrets.VERTEX_AI_PROJECT }}" \
            -e VERTEX_AI_LOCATION="us-central1" \
            -e GOOGLE_APPLICATION_CREDENTIALS="" \
            --name llama-stack-vertex \
            "${{ env.IMAGE_NAME }}:vertex-test-${{ github.sha }}"

          for i in {1..60}; do
            curl -fsS http://127.0.0.1:8321/v1/health 2>/dev/null | grep -q '"status":"OK"' && break
            [ "$i" -eq 60 ] && { docker logs llama-stack-vertex; docker rm -f llama-stack-vertex; exit 1; }
            sleep 1
          done

      - name: Run integration tests (record mode)
        id: run-tests
        env:
          VERTEX_AI_PROJECT: ${{ secrets.VERTEX_AI_PROJECT }}
          LLAMA_STACK_TEST_INFERENCE_MODE: record
        shell: bash
        run: |
          ./tests/run_integration_tests.sh

          # Extract recordings
          WORK_DIR="/tmp/llama-stack-integration-tests"
          RECORDINGS_DIR="$WORK_DIR/tests/integration/recordings"

          [ ! -d "$RECORDINGS_DIR" ] && exit 0

          # Find all recording JSON files (flexible approach - no provider-specific filtering)
          RECORDING_FILES=$(find "$RECORDINGS_DIR" -type f -name "*.json" 2>/dev/null || true)
          [ -z "$RECORDING_FILES" ] && exit 0

          # Copy all recordings to repository (preserving directory structure)
          REPO_RECORDINGS_DIR="tests/integration/recordings"
          mkdir -p "$REPO_RECORDINGS_DIR"
          echo "$RECORDING_FILES" | while IFS= read -r recording; do
            [ -n "$recording" ] && [ -f "$recording" ] && {
              relative_path="${recording#"$RECORDINGS_DIR"/}"
              # Remove leading slash if present
              relative_path="${relative_path#/}"
              mkdir -p "$REPO_RECORDINGS_DIR/$(dirname "$relative_path")"
              cp "$recording" "$REPO_RECORDINGS_DIR/$relative_path"
            }
          done

          # Normalize recordings to reduce git diff noise
          # Use the normalization script from the cloned llama-stack repository
          # The script searches for recordings relative to its location, so we create a temporary
          # symlink in our local repo so it can find our local recordings
          NORMALIZE_SCRIPT="$WORK_DIR/scripts/normalize_recordings.py"
          if [ -f "$NORMALIZE_SCRIPT" ]; then
            TEMP_NORMALIZE_LINK="scripts/normalize_recordings.py"
            ln -sf "$NORMALIZE_SCRIPT" "$TEMP_NORMALIZE_LINK"
            python3 "$TEMP_NORMALIZE_LINK" || echo "Warning: Normalization failed, continuing..."
            rm -f "$TEMP_NORMALIZE_LINK"
          fi
      - name: Cleanup
        if: always()
        run: docker rm -f llama-stack-vertex || true

  create-pr:
    needs: live-tests
    if: always() && needs.live-tests.result == 'success' && github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Extract all recordings and create PR
        env:
          LLAMA_STACK_REPO: https://github.com/llamastack/llama-stack.git
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          REPO_RECORDINGS_DIR="tests/integration/recordings"
          [ ! -d "$REPO_RECORDINGS_DIR" ] && exit 0

          # Check if there are any recordings
          [ -z "$(find "$REPO_RECORDINGS_DIR" -type f)" ] && exit 0

          # Clone llama-stack and update recordings
          LLAMA_STACK_CLONE_DIR=$(mktemp -d)
          git clone "https://x-access-token:$GITHUB_TOKEN@github.com/llamastack/llama-stack.git" "$LLAMA_STACK_CLONE_DIR"
          cd "$LLAMA_STACK_CLONE_DIR"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          BRANCH_NAME="update-recordings-$(date +%Y%m%d-%H%M%S)-${{ github.run_id }}"
          git checkout -b "$BRANCH_NAME"

          TARGET_RECORDINGS_DIR="$LLAMA_STACK_CLONE_DIR/tests/integration/recordings"
          mkdir -p "$TARGET_RECORDINGS_DIR"

          # Copy all recordings
          find "$REPO_RECORDINGS_DIR" -type f | while IFS= read -r recording; do
            relative_path="${recording#"$REPO_RECORDINGS_DIR"/}"
            mkdir -p "$(dirname "$TARGET_RECORDINGS_DIR/$relative_path")"
            cp "$recording" "$TARGET_RECORDINGS_DIR/$relative_path"
          done

          git diff --quiet && exit 0

          git add tests/integration/recordings/
          git commit -m "chore: update test recordings from live tests

          Updated recordings from successful live CI tests run on $(date -u +%Y-%m-%d).
          Generated by: ${{ github.workflow }} workflow
          Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          git push origin "$BRANCH_NAME" || exit 1

          gh auth setup-git
          gh pr create \
            --repo llamastack/llama-stack \
            --title "chore: update test recordings" \
            --body "This PR updates test recordings from successful live CI tests.

          **Source**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          **Date**: $(date -u +%Y-%m-%d)" \
            --head "$BRANCH_NAME" \
            --base main || true
